# FastAgent Configuration File

# Default Model Configuration:
# 
# Takes format:
#   <provider>.<model_string>.<reasoning_effort?> (e.g. anthropic.claude-3-5-sonnet-20241022 or openai.o3-mini.low)
# Accepts aliases for Anthropic Models: haiku, haiku3, sonnet, sonnet35, opus, opus3
# and OpenAI Models: gpt-4o-mini, gpt-4o, o1, o1-mini, o3-mini
#
# If not specified, defaults to "haiku". 
# Can be overriden with a command line switch --model=<model>, or within the Agent constructor.

default_model: anthropic.claude-3-7-sonnet-20250219.low

# Logging and Console Configuration:
logger:
    # type: "none" | "console" | "file" | "http"
    # path: "/path/to/logfile.jsonl"

    
    # Switch the progress display on or off
    progress_display: true

    # Show chat User/Assistant messages on the console
    show_chat: true

    # Show tool calls on the console
    show_tools: false

    # Truncate long tool responses on the console 
    truncate_tools: true
  
mcp:
  servers:
    filesystem:
      command: "npx"
      args: ["-y", "@modelcontextprotocol/server-filesystem", "/Users/sysadmin/Desktop/projects/rabbithole-v2/data/files"]
    memory:
      command: "npx"
      args: ["-y", "@modelcontextprotocol/server-memory"]
      env:
        MEMORY_FILE_PATH: "/Users/sysadmin/Desktop/projects/rabbithole-v2/data/memory.jsonl"
    sequential_thinking:
      command: "npx"
      args: ["-y", "@modelcontextprotocol/server-sequential-thinking"]